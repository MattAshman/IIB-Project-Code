{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01/03/2019\n",
    "\n",
    "Extracting features from each segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/matthewashman/github/MasterProject2018')\n",
    "\n",
    "# Import necessary modules. Set settings. Import data.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.robust import mad\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from FeatureExtraction.feature_tools import detect_peaks\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "import pdb\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "X = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/Data/X_all_channel_labels.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Coupling Interval</th>\n",
       "      <th>Data</th>\n",
       "      <th>Patient</th>\n",
       "      <th>S1/S2</th>\n",
       "      <th>Type</th>\n",
       "      <th>Label 1</th>\n",
       "      <th>Label 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CS1-2</td>\n",
       "      <td>340</td>\n",
       "      <td>[-636, -617, -652, -560, -482, -415, -383, -46...</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>af</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CS1-2</td>\n",
       "      <td>340</td>\n",
       "      <td>[-903.0, -873.0, -935.0, -941.0, -910.0, -845....</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CS1-2</td>\n",
       "      <td>340</td>\n",
       "      <td>[-931.0, -896.0, -896.0, -906.0, -858.0, -839....</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS3-4</td>\n",
       "      <td>340</td>\n",
       "      <td>[472, 464, 491, 523, 553, 706, 1019, 1404, 164...</td>\n",
       "      <td>1</td>\n",
       "      <td>S2</td>\n",
       "      <td>af</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CS3-4</td>\n",
       "      <td>340</td>\n",
       "      <td>[298.0, 292.0, 303.0, 311.0, 299.0, 395.0, 451...</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>af</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Channel Coupling Interval  \\\n",
       "0   CS1-2               340   \n",
       "1   CS1-2               340   \n",
       "2   CS1-2               340   \n",
       "3   CS3-4               340   \n",
       "4   CS3-4               340   \n",
       "\n",
       "                                                Data Patient S1/S2 Type  \\\n",
       "0  [-636, -617, -652, -560, -482, -415, -383, -46...       1    S2   af   \n",
       "1  [-903.0, -873.0, -935.0, -941.0, -910.0, -845....       1    S1   af   \n",
       "2  [-931.0, -896.0, -896.0, -906.0, -858.0, -839....       1    S1   af   \n",
       "3  [472, 464, 491, 523, 553, 706, 1019, 1404, 164...       1    S2   af   \n",
       "4  [298.0, 292.0, 303.0, 311.0, 299.0, 395.0, 451...       1    S1   af   \n",
       "\n",
       "  Label 1 Label 2  \n",
       "0       0       0  \n",
       "1     NaN     NaN  \n",
       "2     NaN     NaN  \n",
       "3       0       0  \n",
       "4     NaN     NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove bad files with bad labels\n",
    "X = X[~(X['Label 1']=='-1') & ~(X['Label 2']=='-1')]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shitty conduction delay detector\n",
    "def get_delay(x, amp_thresh=None, set_thresh=False):\n",
    "    if (set_thresh==True):\n",
    "        if any(abs(x)>amp_thresh):\n",
    "            return np.argmax(abs(x)>amp_thresh)\n",
    "        else:\n",
    "            return len(x)\n",
    "    else:    \n",
    "        return np.argmax(abs(x)>(max(abs(x))/2))\n",
    "    \n",
    "def denoise(x):\n",
    "    # Obtain Daubechies N=6 wavelet coefficients\n",
    "    waveletCoefs = pywt.wavedec(x, 'db7', mode='per')\n",
    "\n",
    "    # Throw away coefficients corresponding to noise\n",
    "    sigma = mad(waveletCoefs[-1])\n",
    "    uThresh = 1*sigma*np.sqrt(2*np.log(len(x)))\n",
    "    denoised = waveletCoefs[:]\n",
    "    denoised[1:] = (pywt._thresholding.hard(i, value=uThresh) for i in denoised[1:])\n",
    "\n",
    "    # Reconstruct the original signal\n",
    "    xDenoised = pywt.waverec(denoised, 'db7', mode='per')\n",
    "\n",
    "    return xDenoised\n",
    "\n",
    "def get_peaks(x, height_thresh, scale_amp=None, set_scale=False, plot = False):\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Get height_thresh\n",
    "    if set_scale:\n",
    "        height_thresh = height_thresh*scale_amp\n",
    "    else:\n",
    "        height_thresh = height_thresh*max(abs(x))\n",
    "    \n",
    "    # Denoise x\n",
    "    xdn = denoise(x)\n",
    "\n",
    "    # Detect peaks using detect_peaks\n",
    "    pos_peak_idx = detect_peaks(xdn, mph=height_thresh, threshold = 0)\n",
    "    neg_peak_idx = detect_peaks((-xdn), mph=height_thresh, threshold = 0)\n",
    "    peak_idx = np.concatenate([pos_peak_idx, neg_peak_idx])\n",
    "    peak_idx = np.sort(peak_idx)\n",
    "    # Edge indeces aren't detected\n",
    "    peak_idx = peak_idx[(peak_idx != 0) & (peak_idx != (len(xdn)-1))]\n",
    "\n",
    "    new_peak_idx = []\n",
    "    peak_amp = []\n",
    "    if (len(peak_idx) > 0):\n",
    "        new_peak_idx.append(peak_idx[0])\n",
    "        mp_thresh = 0.2*max(abs(x))\n",
    "        for i in range(len(peak_idx)-1):\n",
    "            idx = peak_idx[i]\n",
    "            idx_next = peak_idx[i+1]\n",
    "            mid_point = int((idx_next+idx)/2)\n",
    "            if (max([abs(x[idx_next]-x[mid_point]), abs(x[idx]-x[mid_point])]) > mp_thresh):\n",
    "                new_peak_idx.append(idx_next)\n",
    "\n",
    "        peak_idx = np.array(new_peak_idx)\n",
    "        peak_amp = x[peak_idx]\n",
    "\n",
    "    if plot == True:\n",
    "        fig, [ax1] = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(8,8))\n",
    "        ax1.plot(x, 'b' , xdn, 'r--', peak_idx, peak_amp, 'kx')\n",
    "        #plt.title(fileName)\n",
    "        ax1.set_xlabel('Sample')\n",
    "        ax1.set_ylabel('Normalised amplitude')\n",
    "        ax1.legend(['Original segment', 'Denoised segment', 'Detected peaks'])\n",
    "\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress(0) # this will wait for indefinite time\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    return peak_idx, peak_amp\n",
    "\n",
    "def sample_entropy(U, m, r):\n",
    "\n",
    "    def _maxdist(x_i, x_j):\n",
    "        result = max([abs(ua-va) for ua, va in zip(x_i, x_j)])\n",
    "        return result\n",
    "\n",
    "    def _phi(m):\n",
    "        x = np.zeros([N,m-1])\n",
    "        for i in range(N-m+1):\n",
    "            x[i,:] = U[i:i+m-1]\n",
    "\n",
    "        C = 0\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                if i != j:\n",
    "                    if _maxdist(x[i,:], x[j,:]) <= r:\n",
    "                        C = C + 1\n",
    "\n",
    "        return C\n",
    "\n",
    "    U = U/max(abs(U))\n",
    "    N = len(U)\n",
    "\n",
    "    return -np.log(_phi(m+1)/_phi(m))\n",
    "\n",
    "def percentage_fractionation(x, peak_idxs, thresh=0.01, sr=1000):\n",
    "    # Get peak indexes and amplitude\n",
    "    peak_idx_diffs = np.diff(peak_idxs)\n",
    "    frac_time = 0\n",
    "    frac_time = np.sum(peak_idx_diffs[peak_idx_diffs < thresh*sr])\n",
    "    prcnt_frac = (frac_time/len(x))*100\n",
    "    return prcnt_frac\n",
    "\n",
    "def get_local_sample_entropy(x, centre_idx, width, m=2, r=0.05):\n",
    "    # Ensure width is odd\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return sample_entropy(x[:width+1], m, r)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return sample_entropy(x[len(x)-1-width:], m, r)\n",
    "    else:\n",
    "        return sample_entropy(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], m, r)\n",
    "    \n",
    "def get_location_of_max_energy(x, M=14):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    return (np.argmax(x_) + math.floor(M/2))\n",
    "        \n",
    "def get_local_peaks(x, centre_idx, width=25, height_thresh=0.1):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_peaks(x[:width+1], height_thresh)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_peaks(x[len(x)-1-width:], height_thresh)\n",
    "    else:\n",
    "        return get_peaks(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], height_thresh)\n",
    "    \n",
    "def get_pse(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_P = (1/len(x_fft))*np.absolute(x_fft)**2\n",
    "    x_p = x_P/sum(x_P)\n",
    "    pse = np.sum([(-p*np.log2(p)) for p in x_p])\n",
    "    return pse\n",
    "\n",
    "def get_local_pse(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_pse(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_pse(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_pse(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_spectral_centroid(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_spectrum = np.absolute(x_fft)\n",
    "    normalized_spectrum = x_spectrum/sum(x_spectrum)\n",
    "    normalized_frequencies = np.arange(0, len(x_spectrum), 1)\n",
    "    return sum(normalized_frequencies * normalized_spectrum)\n",
    "\n",
    "def get_local_spectral_centroid(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_spectral_centroid(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_spectral_centroid(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_spectral_centroid(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_dict(x, thresh_cd=None, set_thresh_cd=False, thresh_peaks=None, set_thresh_peaks=False, show_peaks=False, col_prefix = ''):\n",
    "    feature_dict = {}\n",
    "    height_thresh=0.1\n",
    "    \n",
    "    # Try normalising x first. Features extracted entirely on shape. Include the max value in features\n",
    "    feature_dict[col_prefix + 'Maximum Absolute Value'] = max(abs(x))\n",
    "    x = x/max(abs(x))\n",
    "    thresh_cd = thresh_cd/max(abs(x))\n",
    "    thresh_peaks = thresh_peaks/max(abs(x))\n",
    "\n",
    "    # First features are hand-engineering\n",
    "    if set_thresh_cd:\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=True'] = get_delay(x, thresh_cd, set_thresh_cd)\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "    else:\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "\n",
    "    if set_thresh_peaks:\n",
    "        peaks = get_peaks(x, height_thresh, thresh_peaks, set_thresh_peaks, plot=False)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=True'] = len(peaks[0])\n",
    "            \n",
    "        peaks = get_peaks(x, height_thresh)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    else:\n",
    "        peaks = get_peaks(x, height_thresh)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    \n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation: thresh=0.01'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    \n",
    "    try:\n",
    "        middle_peak_idx = peaks[0][math.ceil(len(peaks[0])/2)-1]\n",
    "    except:\n",
    "        middle_peak_idx=0\n",
    "\n",
    "    # Denoise x and see if performance is affected\n",
    "    x = denoise(x)\n",
    "    \n",
    "#     # Hand engineered features\n",
    "#     feature_dict[col_prefix + 'Sample Entropy Around Middle Peak: width=40 r=0.05'] = get_local_sample_entropy(x, middle_peak_idx, 40, m=2, r=0.05)\n",
    "#     feature_dict[col_prefix + 'Sample Entropy Around Middle Peak: width=40 r=0.025'] = get_local_sample_entropy(x, middle_peak_idx, 40, m=2, r=0.025)    \n",
    "#     feature_dict[col_prefix + 'Sample Entropy Around Middle Peak: width=20 r=0.05'] = get_local_sample_entropy(x, middle_peak_idx, 20, m=2, r=0.05)\n",
    "#     feature_dict[col_prefix + 'Sample Entropy Around Middle Peak: width=20 r=0.025'] = get_local_sample_entropy(x, middle_peak_idx, 20, m=2, r=0.025)    \n",
    "#     feature_dict[col_prefix + 'Sample Entropy Around Middle Peak: width=60 r=0.05'] = get_local_sample_entropy(x, middle_peak_idx, 60, m=2, r=0.05)\n",
    "#     feature_dict[col_prefix + 'Sample Entropy Around Middle Peak: width=60 r=0.025'] = get_local_sample_entropy(x, middle_peak_idx, 60, m=2, r=0.025)\n",
    "#     feature_dict[col_prefix + 'Sample Entropy'] = sample_entropy(x, m=2, r=0.025)\n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy: M=14'] = max_energy_idx\n",
    "    feature_dict[col_prefix + 'Sample Entropy Around Max Energy: width=60 r=0.025'] = get_local_sample_entropy(x, max_energy_idx, 60, m=2, r=0.025)\n",
    "    min_idx = np.argmin(x)\n",
    "    max_idx = np.argmax(x)\n",
    "    feature_dict[col_prefix + 'Peaks Between Min and Max'] = len([i for i in peaks[0] if ((i > min_idx) & (i < max_idx))])\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy'] = get_pse(x)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid'] = get_spectral_centroid(x)\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy Around Maximum Energy'] = get_local_pse(x, max_energy_idx, width=30)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid Around Maximum Energy'] = get_local_spectral_centroid(x, max_energy_idx, width=30)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Abritrary selection of features from TSFresh\n",
    "    erbc = feature_calculators.energy_ratio_by_chunks(x, [{'num_segments':10, 'segment_focus':3}, {'num_segments':10, 'segment_focus':2}])\n",
    "    feature_dict[col_prefix + 'Energy Ratio by Chunks: num_segments=10 segment_focus=2'] = erbc[1][1]\n",
    "#     feature_dict[col_prefix + 'Approximate Entropy: m=2 r=0.1'] = feature_calculators.approximate_entropy(x, 2, 0.2)\n",
    "#     feature_dict[col_prefix + 'Sample Entropy'] = feature_calculators.sample_entropy(x)\n",
    "    feature_dict[col_prefix + 'Approximate Entropy: m=3 r=0.7'] = feature_calculators.approximate_entropy(x, 3, 0.7)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 5xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 5)\n",
    "    # A fraction q of the mass lies to the left of i. (Alternative to conduction delay?)\n",
    "    imq = feature_calculators.index_mass_quantile(x, [{'q': 0.6}, {'q': 0.4}])\n",
    "    feature_dict[col_prefix + 'Index Mass Quantile: q=0.6'] = imq[0][1]\n",
    "    feature_dict[col_prefix + 'Standard Deviation'] = np.std(x)\n",
    "    feature_dict[col_prefix + 'Normalised Standard Deviation'] = np.std(x/max(abs(x)))\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting Features: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cs12_features_list = []\n",
    "cs34_features_list = []\n",
    "cs56_features_list = []\n",
    "\n",
    "for i,row in X[X['S1/S2']=='S2'].iterrows():\n",
    "    clear_output(wait=True)\n",
    "    display('Extracting Features: ' + str(round((i/X[X['S1/S2']=='S2'].index[-1])*100, 3)) + '%')\n",
    "    \n",
    "    # Get the patients response to the first S1 stimuli as the reference response\n",
    "    ref_response = X[(X['S1/S2']=='S1') & (X['Patient']==row['Patient']) & (X['Type']==row['Type'])\n",
    "                    ].sort_values(by=['Coupling Interval'], ascending=False).iloc[1]\n",
    "    \n",
    "    ref_feature_dict = get_feature_dict(ref_response['Data'], \n",
    "                                        thresh_cd=max(abs(ref_response['Data']))/5, \n",
    "                                        set_thresh_cd=False, \n",
    "                                        thresh_peaks=max(abs(ref_response['Data'])), \n",
    "                                        set_thresh_peaks=True, \n",
    "                                        show_peaks=False, \n",
    "                                        col_prefix = '')\n",
    "    \n",
    "    feature_dict = get_feature_dict(row['Data'],\n",
    "                                    thresh_cd=max(abs(ref_response['Data']))/5, \n",
    "                                    set_thresh_cd=False, \n",
    "                                    thresh_peaks=max(abs(ref_response['Data'])), \n",
    "                                    set_thresh_peaks=True, \n",
    "                                    show_peaks=False, \n",
    "                                    col_prefix = '')\n",
    "    \n",
    "    for k, v in feature_dict.items():\n",
    "        feature_dict[k] = v - ref_feature_dict[k]\n",
    "        \n",
    "    feature_dict['Label 1'] = row['Label 1']\n",
    "    feature_dict['Label 2'] = row['Label 2']\n",
    "    \n",
    "    channel = row['Channel']\n",
    "    if channel=='CS1-2':\n",
    "        cs12_features_list.append(feature_dict)\n",
    "    elif channel=='CS3-4':\n",
    "        cs34_features_list.append(feature_dict)\n",
    "    else:\n",
    "        cs56_features_list.append(feature_dict)\n",
    "        \n",
    "cs12_features = pd.DataFrame(cs12_features_list)\n",
    "cs34_features = pd.DataFrame(cs34_features_list)\n",
    "cs56_features = pd.DataFrame(cs56_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs12_features.to_csv('/Users/matthewashman/github/MasterProject2018/FeatureSelection\\cs12_features_for_mrmr.csv')\n",
    "cs34_features.to_csv('/Users/matthewashman/github/MasterProject2018/FeatureSelection\\cs34_features_for_mrmr.csv')\n",
    "cs56_features.to_csv('/Users/matthewashman/github/MasterProject2018/FeatureSelection\\cs56_features_for_mrmr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
