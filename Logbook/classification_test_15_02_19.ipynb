{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15/02/2019\n",
    "\n",
    "- Compare the performance of different classification models on patient normalised feature vectors. \n",
    "- Plot the segments for which classification mistakes were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from epdata_tools import epdata_main, get_ep_features\n",
    "from IPython.display import HTML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm, naive_bayes, neighbors, gaussian_process\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "import xgboost\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "import pdb\n",
    "\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/Data/X_af.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual dataframes for the data we will be training seperate models on\n",
    "X_CS12_df = X[(X['Channel']=='CS1-2') + (X['S1/S2']=='S2')]\n",
    "X_CS34_df = X[(X['Channel']=='CS3-4') + (X['S1/S2']=='S2')]\n",
    "X_CS56_df = X[(X['Channel']=='CS3-4') + (X['S1/S2']=='S2')]\n",
    "X_CS78_df = X[(X['Channel']=='CS3-4') + (X['S1/S2']=='S2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting Features: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_12, X_34, X_56, X_78, y_12, y_34, y_56, y_78 = [], [], [], [], [], [], [], []\n",
    "ci_12, ci_34, ci_56, ci_78, idx_12, idx_34, idx_56, idx_78 = [], [], [], [], [], [], [], []\n",
    "\n",
    "for i, row in X[(X['S1/S2']=='S2')].iterrows():\n",
    "    clear_output(wait=True)\n",
    "    display('Extracting Features: ' + str(round(100*i/X[(X['S1/S2']=='S2')].index[-1],3)) + '%')\n",
    "    coupling_interval = row['Coupling Interval']\n",
    "    channel = row['Channel']\n",
    "    data = row['Data']\n",
    "    label = row['Label']\n",
    "    patient = row['Patient']\n",
    "    typical_s1 = X[(X['S1/S2']=='S1') & (X['Channel']==channel) & (X['Patient']==patient)].iloc[0]['Data']\n",
    "    typical_s1_fv = get_ep_features(typical_s1)\n",
    "    \n",
    "    fv = get_ep_features(data)\n",
    "    fv -= typical_s1_fv\n",
    "    \n",
    "    if(channel == 'CS1-2'):\n",
    "        X_12.append(fv)\n",
    "        y_12.append(int(label))\n",
    "        ci_12.append(int(coupling_interval))\n",
    "        idx_12.append(i)\n",
    "    elif(channel == 'CS3-4'):\n",
    "        X_34.append(fv)\n",
    "        y_34.append(int(label))\n",
    "        ci_34.append(int(coupling_interval))\n",
    "        idx_34.append(i)\n",
    "    elif(channel == 'CS5-6'):\n",
    "        X_56.append(fv)\n",
    "        y_56.append(int(label))\n",
    "        ci_56.append(int(coupling_interval))\n",
    "        idx_56.append(i)\n",
    "    elif(channel == 'CS7-8'):\n",
    "        X_78.append(fv)\n",
    "        y_78.append(int(label))\n",
    "        ci_78.append(int(coupling_interval))\n",
    "        idx_78.append(i)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 11)\n",
      "(128, 11)\n",
      "(128, 11)\n",
      "(128, 11)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "X_12 = np.asarray(X_12); y_12 = np.asarray(y_12); ci_12 = np.asarray(ci_12); idx_12 = np.asarray(idx_12)\n",
    "X_34 = np.asarray(X_34); y_34 = np.asarray(y_34); ci_34 = np.asarray(ci_34); idx_34 = np.asarray(idx_34)\n",
    "X_56 = np.asarray(X_56); y_56 = np.asarray(y_56); ci_56 = np.asarray(ci_56); idx_56 = np.asarray(idx_56)\n",
    "X_78 = np.asarray(X_78); y_78 = np.asarray(y_78); ci_78 = np.asarray(ci_78); idx_78 = np.asarray(idx_78)\n",
    "\n",
    "print(X_12.shape); print(X_34.shape); print(X_56.shape); print(X_78.shape)\n",
    "print(y_12.shape); print(y_34.shape); print(y_56.shape); print(y_78.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_errors = (y_12 != -1) & (y_34 != -1) & (y_34 != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_array = np.concatenate((ci_12.reshape(-1,1), X_12, X_34, X_56),axis=1) including coupling intervals as features appears to have a negative impact on performance\n",
    "X_array = np.concatenate((X_12, X_34, X_56),axis=1)\n",
    "# Removes occurances of errors\n",
    "X_array = X_array[no_errors]\n",
    "y = np.logical_or(y_12, y_34, y_56).astype(int)\n",
    "# Removes occurances of errors\n",
    "y = y[no_errors]\n",
    "idx = np.concatenate((idx_12.reshape(-1,1),idx_34.reshape(-1,1), idx_56.reshape(-1,1)),axis=1)\n",
    "# Removes occurances of errors\n",
    "idx = idx[no_errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove occurances of errors from original labels\n",
    "X_12 = X_12[y_12 != -1]; idx_12 = idx_12[y_12 != -1]; y_12 = y_12[y_12 != -1]\n",
    "y_34 = y_34[y_34 != -1]; idx_34 = idx_34[y_34 != -1]; y_34 = y_34[y_34 != -1]\n",
    "y_56 = y_56[y_56 != -1]; idx_56 = idx_56[y_56 != -1]; y_56 = y_56[y_56 != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_12_train, X_12_test, y_12_train, y_12_test, idx_12_train, idx_12_test = train_test_split(X_12, y_12, idx_12, test_size=0.3)\n",
    "X_34_train, X_34_test, y_34_train, y_34_test, idx_34_train, idx_34_test = train_test_split(X_34, y_34, idx_34, test_size=0.3)\n",
    "X_56_train, X_56_test, y_56_train, y_56_test, idx_56_train, idx_56_test = train_test_split(X_56, y_56, idx_56, test_size=0.3)\n",
    "X_78_train, X_78_test, y_78_train, y_78_test, idx_78_train, idx_78_test = train_test_split(X_78, y_78, idx_78, test_size=0.3)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(X_array, y, idx, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores on combined data:\n",
      "SVM\n",
      "[0.77777778 0.77777778 0.77777778]\n",
      "Naive Bayes\n",
      "[0.81481481 0.96296296 0.88888889]\n",
      "KNN\n",
      "[0.77777778 0.81481481 0.77777778]\n",
      "GP\n",
      "[0.77777778 0.77777778 0.77777778]\n",
      "XGBoost\n",
      "[0.88888889 0.92592593 1.        ]\n",
      "Cross validation scores on CS1-2 data:\n",
      "SVM\n",
      "[0.81481481 0.81481481 0.81481481]\n",
      "Naive Bayes\n",
      "[0.92592593 1.         0.92592593]\n",
      "KNN\n",
      "[0.7037037  0.77777778 0.85185185]\n",
      "GP\n",
      "[0.85185185 0.81481481 0.88888889]\n",
      "XGBoost\n",
      "[0.96296296 0.96296296 0.96296296]\n",
      "Cross validation scores on CS3-4 data:\n",
      "SVM\n",
      "[0.83333333 0.83333333 0.86206897]\n",
      "Naive Bayes\n",
      "[0.9        0.8        0.82758621]\n",
      "KNN\n",
      "[0.9        0.93333333 0.89655172]\n",
      "GP\n",
      "[0.9        0.93333333 0.89655172]\n",
      "XGBoost\n",
      "[0.9        0.86666667 0.89655172]\n",
      "Cross validation scores on CS5-6 data:\n",
      "SVM\n",
      "[0.66666667 0.66666667 0.68965517]\n",
      "Naive Bayes\n",
      "[0.83333333 0.86666667 0.86206897]\n",
      "KNN\n",
      "[0.76666667 0.73333333 0.75862069]\n",
      "GP\n",
      "[0.7        0.63333333 0.79310345]\n",
      "XGBoost\n",
      "[0.76666667 0.76666667 0.86206897]\n",
      "Cross validation scores on CS7-8 data:\n",
      "SVM\n",
      "[0.93548387 0.96551724 0.96551724]\n",
      "Naive Bayes\n",
      "[0.93548387 0.89655172 0.96551724]\n",
      "KNN\n",
      "[0.93548387 0.96551724 0.96551724]\n",
      "GP\n",
      "[0.93548387 0.89655172 0.93103448]\n",
      "XGBoost\n",
      "[0.93548387 0.96551724 0.96551724]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "models = (svm.SVC(), naive_bayes.GaussianNB(), neighbors.KNeighborsClassifier(), \n",
    "          gaussian_process.GaussianProcessClassifier(kernel=1.0*RBF(1)), xgboost.XGBClassifier())\n",
    "model_names = ('SVM', 'Naive Bayes', 'KNN', 'GP', 'XGBoost')\n",
    "print('Cross validation scores on combined data:')\n",
    "for clf, model_name in zip(models, model_names):\n",
    "    print(model_name)\n",
    "    print(cross_val_score(clf, X_train, y_train, cv=3))\n",
    "    \n",
    "print('Cross validation scores on CS1-2 data:')\n",
    "for clf, model_name in zip(models, model_names):\n",
    "    print(model_name)\n",
    "    print(cross_val_score(clf, X_12_train, y_12_train, cv=3))\n",
    "    \n",
    "print('Cross validation scores on CS3-4 data:')\n",
    "for clf, model_name in zip(models, model_names):\n",
    "    print(model_name)\n",
    "    print(cross_val_score(clf, X_34_train, y_34_train, cv=3))\n",
    "    \n",
    "print('Cross validation scores on CS5-6 data:')\n",
    "for clf, model_name in zip(models, model_names):\n",
    "    print(model_name)\n",
    "    print(cross_val_score(clf, X_56_train, y_56_train, cv=3))\n",
    "    \n",
    "print('Cross validation scores on CS7-8 data:')\n",
    "for clf, model_name in zip(models, model_names):\n",
    "    print(model_name)\n",
    "    print(cross_val_score(clf, X_78_train, y_78_train, cv=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score on CS1-2 data:\n",
      "0.9444444444444444\n",
      "Test score on CS3-4 data:\n",
      "0.9230769230769231\n",
      "Test score on CS5-6 data:\n",
      "0.8461538461538461\n",
      "Test score on CS7-8 data:\n",
      "1.0\n",
      "Test score on combined data:\n",
      "0.9444444444444444\n",
      "[[0 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "clf = xgboost.XGBClassifier()\n",
    "print('Test score on CS1-2 data:')\n",
    "clf.fit(X_12_train, y_12_train)\n",
    "print(clf.score(X_12_test, y_12_test))\n",
    "print('Test score on CS3-4 data:')\n",
    "clf.fit(X_34_train, y_34_train)\n",
    "print(clf.score(X_34_test, y_34_test))\n",
    "print('Test score on CS5-6 data:')\n",
    "clf.fit(X_56_train, y_56_train)\n",
    "print(clf.score(X_56_test, y_56_test))\n",
    "print('Test score on CS7-8 data:')\n",
    "clf.fit(X_78_train, y_78_train)\n",
    "print(clf.score(X_78_test, y_78_test))\n",
    "print('Test score on combined data:')\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "predictions = clf.predict(X_test)\n",
    "mistake_idxs = idx_test[predictions != y_test]\n",
    "mistake_labels = np.concatenate((predictions[predictions != y_test].reshape(-1,1), y_test[predictions != y_test].reshape(-1,1)), axis=1)\n",
    "\n",
    "mistake_idxs = np.squeeze(mistake_idxs)\n",
    "\n",
    "print(mistake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels] + [5])  # 5 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    \n",
    "    # Begin CHANGES\n",
    "    fst_empty_cell = (columnwidth-3)//2 * \" \" + \"t/p\" + (columnwidth-3)//2 * \" \"\n",
    "    \n",
    "    if len(fst_empty_cell) < len(empty_cell):\n",
    "        fst_empty_cell = \" \" * (len(empty_cell) - len(fst_empty_cell)) + fst_empty_cell\n",
    "    # Print header\n",
    "    print(\"    \" + fst_empty_cell, end=\" \")\n",
    "    # End CHANGES\n",
    "    \n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % label, end=\" \")\n",
    "        \n",
    "    print()\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           t/p       Not Fractionated     Fractionated \n",
      "    Not Fractionated             27.0              0.0 \n",
      "        Fractionated              2.0              7.0 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print_cm(cm, ['Not Fractionated','Fractionated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  96,   99,  102],\n",
       "       [1156, 1159, 1162]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistake_idxs = np.squeeze(mistake_idxs)\n",
    "mistake_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt \n",
    "for i, [cs12_idx, cs34_idx, cs56_idx] in enumerate(mistake_idxs):\n",
    "    patient = X['Patient'].loc[cs12_idx]\n",
    "    coupling_interval = X['Coupling Interval'].loc[cs12_idx]\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12,4))\n",
    "    [ax1, ax2, ax3] = axes.flatten()\n",
    "    ax1.plot(X['Data'].loc[cs12_idx])\n",
    "    ax1.set_title('CS1-2')\n",
    "    ax2.plot(X['Data'].loc[cs34_idx])\n",
    "    ax2.set_title('CS3-4')\n",
    "    ax3.plot(X['Data'].loc[cs56_idx])\n",
    "    ax3.set_title('CS5-6')\n",
    "    plt.suptitle('Patient: ' + patient + ' Coupling Interval: ' + coupling_interval + '\\n Predicted label: ' + str(mistake_labels[i,0]) + ' True label: ' + str(mistake_labels[i,1]))\n",
    "    plt.subplots_adjust(top = 0.8, bottom = 0.2)\n",
    "    plt.draw()\n",
    "    plt.waitforbuttonpress()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
