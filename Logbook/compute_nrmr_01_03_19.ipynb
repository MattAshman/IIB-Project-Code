{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01/03/2019\n",
    "- Trying to implement the use of nrmr in feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrmr_mid_d(d, f, K):\n",
    "\n",
    "    fea = np.zeros(K)\n",
    "    mi_array = []\n",
    "    \n",
    "    nd = d.shape[1]\n",
    "    nc = d.shape[0]\n",
    "    # Simply calculate the MI between the feature and the targets. Store in t\n",
    "    t = mutual_info_classif(d, f)\n",
    "    \n",
    "    # Sort in descending order (i.e. biggest mutual information first)\n",
    "    tmp = np.sort(-t)\n",
    "    # Keep indices of features\n",
    "    idxs = np.argsort(-t)\n",
    "    fea_base = idxs[0:K]\n",
    "    \n",
    "    # First feature index\n",
    "    fea[0] = idxs[0]\n",
    "    # KMAX = max number to use\n",
    "    KMAX = np.min(1000, nd)\n",
    "    # Index of features remaining\n",
    "    idxleft = idxs[1:KMAX]\n",
    "    \n",
    "    t_mi = np.zeros(len(idxleft))\n",
    "    mi_array = np.zeros([len(idxleft), K])\n",
    "    for k in range(1, K):\n",
    "        # Number of candidate features\n",
    "        ncand = len(idxleft)\n",
    "        # Current last fea?\n",
    "        curlastfea = len(fea)-1\n",
    "        # Loop through candidate features\n",
    "        for i in range(ncand):\n",
    "            # Mutual information between feature and target\n",
    "            t_mi = mutual_info_classif(d[:,idxleft], f)\n",
    "            # Mutual Information between features\n",
    "            mi_array[idxleft,curlastfea] = getmultimi(d[:,fea[curlastfea]], d[:,idxleft])\n",
    "            c_mi = np.mean(mi_array[idxleft[i], :]); \n",
    "            \n",
    "        tmp = np.max(t_mi[1:ncand] - c_mi[1:ncand])\n",
    "        tmpidx = fea[k]\n",
    "        fea[k] = np.argmax(t_mi[1:ncand] - c_mi[1:ncand])\n",
    "        idxleft[tmpidx] = []\n",
    "        \n",
    "    return fea\n",
    "        \n",
    "\n",
    "def getmultimi(da, dt):\n",
    "    return mutual_info_classif(da, dt);\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs12_features = pd.read_csv('/Users/matthewashman/github/MasterProject2018/FeatureSelection/cs12_features_for_mrmr.csv')\n",
    "cs34_features = pd.read_csv('/Users/matthewashman/github/MasterProject2018/FeatureSelection/cs34_features_for_mrmr.csv')\n",
    "cs56_features = pd.read_csv('/Users/matthewashman/github/MasterProject2018/FeatureSelection/cs56_features_for_mrmr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs12_features = cs12_features.drop(['Unnamed: 0'], axis=1)\n",
    "cs34_features = cs34_features.drop(['Unnamed: 0'], axis=1)\n",
    "cs56_features = cs56_features.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cs12 = cs12_features['Label 1'].values\n",
    "X_cs12 = cs12_features.drop(['Label 1', 'Label 2'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-1.15071962e-03 -9.11145321e-05 -1.08569785e-03 -1.58241752e-03\n -1.06984873e-03 -1.69026876e-03  7.03035774e-03  5.03710241e-02\n  9.98872642e-03  1.66415934e-02  3.37297839e-02  2.28874499e-02\n -5.84571670e-03  4.92438133e-03  7.69667142e-03 -3.23269263e-03\n  3.91561501e-03 -6.46637445e-03 -1.57750264e-03  2.45269098e-02\n  6.08858601e-03 -9.32218499e-03 -1.95524303e-03  4.31367918e-03\n  4.21501749e-05 -2.20318442e-03 -4.26621566e-03  1.36538333e-03\n -2.33117719e-02  1.20091827e-02  1.80729300e-02  1.67272761e-02\n -1.08325240e-02 -3.06539558e-04  5.50268765e-03  1.87556155e-02\n  4.92147441e-03 -1.45765947e-02  1.44485910e-02  7.78071326e-03\n  5.42583236e-02 -2.20042469e-04 -1.71167982e-02  5.66737540e-02\n  5.22281763e-02  4.80418933e-02  4.51903067e-02  5.51211124e-02\n  4.30967246e-02  4.37629962e-02  5.14725860e-02  6.03818376e-02\n  4.87065889e-02  4.89584746e-02  4.14907484e-02  5.58201450e-02\n  4.82591854e-02  4.70372749e-02  4.68524811e-02  5.22955633e-02\n  3.50257561e-02  6.05351948e-02  4.46907292e-02  7.27193133e-02\n  1.15637994e-01  8.21401160e-02  1.10286139e-01  6.60081229e-02\n  1.12030267e-02  3.73748901e-03  1.17292112e-02  8.27861653e-03\n  1.28694378e-02  2.10131135e-02  3.85581218e-02 -5.84291341e-03\n  6.85017158e-03 -3.40297639e-04  1.18043253e-01  3.58910761e-02\n  4.26429248e-02  1.71515331e-02  2.04092159e-02  2.71106023e-02\n  4.59948637e-02  1.27931487e-02  4.09404943e-02  1.23191866e-01\n  6.48787678e-02  4.80571891e-02  1.10722445e-01  1.29334903e-01\n  1.39503872e-01  1.20613407e-01  9.11520089e-02 -1.60363630e-02\n  7.70737069e-03  1.65100119e-02  1.96464956e-03  3.91974424e-02\n  6.72948237e-02  9.00875537e-03  7.85895338e-02  7.89299127e-02\n  9.94796677e-02  1.53273804e-01  4.23604683e-02  2.79529623e-03\n  2.42570014e-02  4.29792578e-02  8.42102938e-02  1.29303652e-01\n  1.33753594e-01  1.77708672e-01  1.54340923e-01  1.59142596e-01\n  1.69655045e-01 -6.49751469e-03  6.17499015e-02  2.00389865e-02\n  1.43189207e-02  9.22916397e-02  3.78757822e-02  7.11017526e-02\n  6.15736085e-02  3.40506767e-02  2.79234688e-02  3.28999293e-02\n  1.70578251e-04  4.02437369e-02  3.34312639e-02  4.59802489e-02\n  5.24281733e-02  3.35659881e-02  3.48427746e-02  2.93102655e-02\n  3.09836137e-02  3.25330707e-02  4.55821103e-02  4.44313350e-02\n  4.06103776e-02  3.75758014e-02  3.06900180e-02  2.75804088e-02\n  6.30746832e-02  9.18581941e-02  1.22359473e-01  1.58353918e-01\n  1.26591711e-01  2.12997530e-01  2.11487444e-01  1.51245291e-01\n  2.16453375e-02  3.57444864e-02  3.13528756e-02  7.42152110e-02\n  5.25801625e-02  8.69540781e-02  8.61012127e-02  9.53499692e-02\n  7.73919466e-02 -5.22294616e-02 -5.58021683e-02 -3.76526007e-02\n -4.05968255e-02 -2.68456040e-02 -4.57122809e-02 -2.46527221e-02\n -1.98364895e-02  4.40104544e-02  4.39957224e-02  5.95813432e-02\n  5.81060110e-02  4.76910872e-02  4.30275199e-02  7.33190925e-02\n  6.41265496e-02  9.35478718e-03  9.40263090e-03  2.15668399e-02\n  1.33787464e-02  2.97160617e-03  3.65889558e-03 -5.18294592e-04\n  4.01660777e-03  8.08104477e-03  6.95155792e-03  1.33335431e-02\n  9.38664958e-04 -1.25193624e-03 -5.00765589e-03 -4.90954036e-03\n  1.02674654e-02  7.79624896e-03  9.86973608e-03  3.45849949e-03\n  5.57778154e-03  3.95727896e-03  1.07070059e-02  7.98564234e-03\n  6.39192929e-03  4.30818630e-02  5.30593419e-02  3.89046728e-02\n  4.34395752e-02  4.63745253e-02  5.27565104e-02 -4.43355670e-02\n -4.38050719e-02 -4.39066718e-02 -4.39014957e-02 -4.42146674e-02\n -4.38022848e-02 -4.42223609e-02 -4.38245427e-02 -4.35231191e-02\n -4.35994508e-02 -4.39748302e-02 -4.37962386e-02 -3.01479099e-02\n -6.44865714e-03 -1.76619130e-03  2.52280059e-02  3.28294087e-02\n  6.98287862e-02  2.42886777e-02  5.67016340e-03  1.19030345e-03\n  1.77267288e-02  7.70938737e-02 -9.97866040e-03  3.45154323e-02\n -1.54264240e-02 -2.13540453e-02  3.21277964e-02  1.61880780e-02\n  2.87005754e-02 -1.23772643e-02 -7.96657968e-03 -3.08049595e-03\n  1.40382863e-02  1.84161840e-02 -2.25538061e-02  1.17745901e-02\n  4.67279012e-03 -3.83602130e-02 -3.52417207e-02 -3.49678379e-02\n -1.47358698e-02  7.57842719e-03  5.61878338e-03  4.84568708e-03\n  8.35336658e-03  6.53093644e-03  1.12452203e-02  8.88872210e-03\n  2.35750116e-02  1.14294970e-02  2.57278302e-03  2.32283048e-02\n  4.35670811e-03  1.09940826e-02  2.29545764e-02 -7.22916535e-03\n  6.68935955e-02  3.49871360e-02  1.14966285e-01 -2.74350594e-02\n -1.98486207e-02 -1.42131210e-03  8.45368667e-03  6.18857348e-03\n  3.49515633e-03 -1.27335053e-03 -1.39330290e-03 -1.22075744e-03\n -1.19408109e-03  3.39766577e-03 -9.49447069e-04 -9.32043375e-05\n  3.93638816e-03 -1.07672081e-03 -1.24816468e-02  2.49252489e-02\n  9.00299944e-02  1.31193188e-02  1.69950874e-02  5.39141097e-02\n  5.19821994e-02  3.06190975e-03  7.95723582e-03 -4.78616209e-03\n  8.96239679e-04 -3.70550162e-03 -1.19360842e-02 -2.08576651e-02\n -5.09392550e-03 -1.28347460e-02 -9.39352835e-03 -1.01591613e-02\n -1.21512916e-02  7.27466005e-02  5.63465511e-02  5.79021394e-02\n  3.32678943e-02  4.12013839e-02  1.71462008e-02  8.20916699e-02\n  1.47110503e-02  1.00340029e-01  7.05937926e-02  6.25114629e-02\n  2.62500387e-02  4.21853988e-02  3.56880034e-02  2.77438456e-02\n  3.87796679e-02  4.33275739e-02  1.22229344e-01  6.80395722e-02\n  7.77062729e-02  1.69541325e-02  7.68668490e-03  1.69423057e-03\n  2.49602208e-02  3.65837346e-02  5.36565819e-02  4.42157839e-02\n  1.77612793e-02  2.83349135e-02  2.78504434e-02  1.24238820e-02\n  1.62934061e-02  4.26889775e-02  3.58765045e-02  4.84254895e-02\n  5.48734139e-02  3.60112288e-02  3.72880152e-02  3.17555062e-02\n  3.34288544e-02  1.05874938e-01  9.18756721e-02  1.15721297e-01\n  7.02034271e-02  1.32532089e-01  9.70546491e-02  9.25869129e-02\n  7.66941547e-02  6.55641769e-02  6.75851908e-02  5.77918620e-02\n  7.13733411e-02  7.42671402e-02  7.34822078e-02  6.69706066e-02\n  3.01033337e-02 -9.46438231e-04  1.00917447e-02  6.17850829e-03\n  2.60032970e-02  2.23934832e-02  6.82196220e-03  1.39924272e-02\n  1.22185731e-02  1.47371200e-02  2.53903028e-02  1.26000579e-02\n  3.76032452e-02  3.85623239e-02  5.40662607e-02  9.41949220e-02\n  6.86719653e-02  5.56130812e-03 -2.34069661e-02 -2.28289383e-02\n  1.35158386e-03  4.63211012e-02  3.69509730e-02  2.81381684e-02\n  2.68051968e-02  9.90262096e-03  1.44378663e-02  4.14691633e-02\n  2.42790106e-02 -2.94882919e-02 -3.34986032e-02  1.36103371e-02\n  2.47788867e-03 -7.65453956e-02 -7.23855976e-02 -6.48802493e-02\n -4.67204467e-02 -3.98346956e-02 -6.22799966e-02  2.14144633e-02\n  6.09602659e-03  8.24858555e-03  5.51108399e-03  6.36313824e-03\n  5.87961051e-03  4.76054708e-03  5.36249444e-03 -6.25538887e-04\n  5.77683666e-03  5.78482455e-03  3.76133303e-04  1.09571209e-02\n  8.55687376e-03  8.91081378e-02  1.38867443e-01  1.17189085e-01\n  7.48817241e-02  8.96374447e-02  9.69234364e-02  9.56841907e-02\n  7.50353323e-02  8.96054717e-02  5.46178600e-02  3.72236821e-02\n  4.10912126e-02  3.99118257e-02  4.35493463e-02  4.24890466e-02\n  4.28602741e-02  3.87376563e-02  3.71977985e-02  2.89273508e-02\n  3.40759024e-02  6.43848665e-02  6.15849911e-03  6.44208942e-04\n -3.09259997e-03  1.32164686e-02  1.72367865e-02 -9.09120115e-03\n -9.09698251e-03  1.55277923e-02  4.71421186e-03 -9.01860213e-03\n  1.66468748e-02  1.03668357e-03  1.02593413e-03 -3.57328711e-03\n -1.28142153e-02 -9.45846941e-03 -7.13603875e-03  3.24858548e-03\n  9.31980221e-03  4.03848806e-03 -5.59836033e-03].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cc3dc3a8725a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmrmr_mid_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_cs12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_cs12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-d4ada5c5301e>\u001b[0m in \u001b[0;36mmrmr_mid_d\u001b[0;34m(d, f, K)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Simply calculate the MI between the feature and the targets. Store in t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_classif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Sort in descending order (i.e. biggest mutual information first)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/mutual_info_.py\u001b[0m in \u001b[0;36mmutual_info_classif\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     return _estimate_mi(X, y, discrete_features, True, n_neighbors,\n\u001b[0;32m--> 450\u001b[0;31m                         copy, random_state)\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/mutual_info_.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state)\u001b[0m\n\u001b[1;32m    246\u001b[0m            \u001b[0mData\u001b[0m \u001b[0mSets\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mPLoS\u001b[0m \u001b[0mONE\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2014.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;31m# To ensure that array flags are maintained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-1.15071962e-03 -9.11145321e-05 -1.08569785e-03 -1.58241752e-03\n -1.06984873e-03 -1.69026876e-03  7.03035774e-03  5.03710241e-02\n  9.98872642e-03  1.66415934e-02  3.37297839e-02  2.28874499e-02\n -5.84571670e-03  4.92438133e-03  7.69667142e-03 -3.23269263e-03\n  3.91561501e-03 -6.46637445e-03 -1.57750264e-03  2.45269098e-02\n  6.08858601e-03 -9.32218499e-03 -1.95524303e-03  4.31367918e-03\n  4.21501749e-05 -2.20318442e-03 -4.26621566e-03  1.36538333e-03\n -2.33117719e-02  1.20091827e-02  1.80729300e-02  1.67272761e-02\n -1.08325240e-02 -3.06539558e-04  5.50268765e-03  1.87556155e-02\n  4.92147441e-03 -1.45765947e-02  1.44485910e-02  7.78071326e-03\n  5.42583236e-02 -2.20042469e-04 -1.71167982e-02  5.66737540e-02\n  5.22281763e-02  4.80418933e-02  4.51903067e-02  5.51211124e-02\n  4.30967246e-02  4.37629962e-02  5.14725860e-02  6.03818376e-02\n  4.87065889e-02  4.89584746e-02  4.14907484e-02  5.58201450e-02\n  4.82591854e-02  4.70372749e-02  4.68524811e-02  5.22955633e-02\n  3.50257561e-02  6.05351948e-02  4.46907292e-02  7.27193133e-02\n  1.15637994e-01  8.21401160e-02  1.10286139e-01  6.60081229e-02\n  1.12030267e-02  3.73748901e-03  1.17292112e-02  8.27861653e-03\n  1.28694378e-02  2.10131135e-02  3.85581218e-02 -5.84291341e-03\n  6.85017158e-03 -3.40297639e-04  1.18043253e-01  3.58910761e-02\n  4.26429248e-02  1.71515331e-02  2.04092159e-02  2.71106023e-02\n  4.59948637e-02  1.27931487e-02  4.09404943e-02  1.23191866e-01\n  6.48787678e-02  4.80571891e-02  1.10722445e-01  1.29334903e-01\n  1.39503872e-01  1.20613407e-01  9.11520089e-02 -1.60363630e-02\n  7.70737069e-03  1.65100119e-02  1.96464956e-03  3.91974424e-02\n  6.72948237e-02  9.00875537e-03  7.85895338e-02  7.89299127e-02\n  9.94796677e-02  1.53273804e-01  4.23604683e-02  2.79529623e-03\n  2.42570014e-02  4.29792578e-02  8.42102938e-02  1.29303652e-01\n  1.33753594e-01  1.77708672e-01  1.54340923e-01  1.59142596e-01\n  1.69655045e-01 -6.49751469e-03  6.17499015e-02  2.00389865e-02\n  1.43189207e-02  9.22916397e-02  3.78757822e-02  7.11017526e-02\n  6.15736085e-02  3.40506767e-02  2.79234688e-02  3.28999293e-02\n  1.70578251e-04  4.02437369e-02  3.34312639e-02  4.59802489e-02\n  5.24281733e-02  3.35659881e-02  3.48427746e-02  2.93102655e-02\n  3.09836137e-02  3.25330707e-02  4.55821103e-02  4.44313350e-02\n  4.06103776e-02  3.75758014e-02  3.06900180e-02  2.75804088e-02\n  6.30746832e-02  9.18581941e-02  1.22359473e-01  1.58353918e-01\n  1.26591711e-01  2.12997530e-01  2.11487444e-01  1.51245291e-01\n  2.16453375e-02  3.57444864e-02  3.13528756e-02  7.42152110e-02\n  5.25801625e-02  8.69540781e-02  8.61012127e-02  9.53499692e-02\n  7.73919466e-02 -5.22294616e-02 -5.58021683e-02 -3.76526007e-02\n -4.05968255e-02 -2.68456040e-02 -4.57122809e-02 -2.46527221e-02\n -1.98364895e-02  4.40104544e-02  4.39957224e-02  5.95813432e-02\n  5.81060110e-02  4.76910872e-02  4.30275199e-02  7.33190925e-02\n  6.41265496e-02  9.35478718e-03  9.40263090e-03  2.15668399e-02\n  1.33787464e-02  2.97160617e-03  3.65889558e-03 -5.18294592e-04\n  4.01660777e-03  8.08104477e-03  6.95155792e-03  1.33335431e-02\n  9.38664958e-04 -1.25193624e-03 -5.00765589e-03 -4.90954036e-03\n  1.02674654e-02  7.79624896e-03  9.86973608e-03  3.45849949e-03\n  5.57778154e-03  3.95727896e-03  1.07070059e-02  7.98564234e-03\n  6.39192929e-03  4.30818630e-02  5.30593419e-02  3.89046728e-02\n  4.34395752e-02  4.63745253e-02  5.27565104e-02 -4.43355670e-02\n -4.38050719e-02 -4.39066718e-02 -4.39014957e-02 -4.42146674e-02\n -4.38022848e-02 -4.42223609e-02 -4.38245427e-02 -4.35231191e-02\n -4.35994508e-02 -4.39748302e-02 -4.37962386e-02 -3.01479099e-02\n -6.44865714e-03 -1.76619130e-03  2.52280059e-02  3.28294087e-02\n  6.98287862e-02  2.42886777e-02  5.67016340e-03  1.19030345e-03\n  1.77267288e-02  7.70938737e-02 -9.97866040e-03  3.45154323e-02\n -1.54264240e-02 -2.13540453e-02  3.21277964e-02  1.61880780e-02\n  2.87005754e-02 -1.23772643e-02 -7.96657968e-03 -3.08049595e-03\n  1.40382863e-02  1.84161840e-02 -2.25538061e-02  1.17745901e-02\n  4.67279012e-03 -3.83602130e-02 -3.52417207e-02 -3.49678379e-02\n -1.47358698e-02  7.57842719e-03  5.61878338e-03  4.84568708e-03\n  8.35336658e-03  6.53093644e-03  1.12452203e-02  8.88872210e-03\n  2.35750116e-02  1.14294970e-02  2.57278302e-03  2.32283048e-02\n  4.35670811e-03  1.09940826e-02  2.29545764e-02 -7.22916535e-03\n  6.68935955e-02  3.49871360e-02  1.14966285e-01 -2.74350594e-02\n -1.98486207e-02 -1.42131210e-03  8.45368667e-03  6.18857348e-03\n  3.49515633e-03 -1.27335053e-03 -1.39330290e-03 -1.22075744e-03\n -1.19408109e-03  3.39766577e-03 -9.49447069e-04 -9.32043375e-05\n  3.93638816e-03 -1.07672081e-03 -1.24816468e-02  2.49252489e-02\n  9.00299944e-02  1.31193188e-02  1.69950874e-02  5.39141097e-02\n  5.19821994e-02  3.06190975e-03  7.95723582e-03 -4.78616209e-03\n  8.96239679e-04 -3.70550162e-03 -1.19360842e-02 -2.08576651e-02\n -5.09392550e-03 -1.28347460e-02 -9.39352835e-03 -1.01591613e-02\n -1.21512916e-02  7.27466005e-02  5.63465511e-02  5.79021394e-02\n  3.32678943e-02  4.12013839e-02  1.71462008e-02  8.20916699e-02\n  1.47110503e-02  1.00340029e-01  7.05937926e-02  6.25114629e-02\n  2.62500387e-02  4.21853988e-02  3.56880034e-02  2.77438456e-02\n  3.87796679e-02  4.33275739e-02  1.22229344e-01  6.80395722e-02\n  7.77062729e-02  1.69541325e-02  7.68668490e-03  1.69423057e-03\n  2.49602208e-02  3.65837346e-02  5.36565819e-02  4.42157839e-02\n  1.77612793e-02  2.83349135e-02  2.78504434e-02  1.24238820e-02\n  1.62934061e-02  4.26889775e-02  3.58765045e-02  4.84254895e-02\n  5.48734139e-02  3.60112288e-02  3.72880152e-02  3.17555062e-02\n  3.34288544e-02  1.05874938e-01  9.18756721e-02  1.15721297e-01\n  7.02034271e-02  1.32532089e-01  9.70546491e-02  9.25869129e-02\n  7.66941547e-02  6.55641769e-02  6.75851908e-02  5.77918620e-02\n  7.13733411e-02  7.42671402e-02  7.34822078e-02  6.69706066e-02\n  3.01033337e-02 -9.46438231e-04  1.00917447e-02  6.17850829e-03\n  2.60032970e-02  2.23934832e-02  6.82196220e-03  1.39924272e-02\n  1.22185731e-02  1.47371200e-02  2.53903028e-02  1.26000579e-02\n  3.76032452e-02  3.85623239e-02  5.40662607e-02  9.41949220e-02\n  6.86719653e-02  5.56130812e-03 -2.34069661e-02 -2.28289383e-02\n  1.35158386e-03  4.63211012e-02  3.69509730e-02  2.81381684e-02\n  2.68051968e-02  9.90262096e-03  1.44378663e-02  4.14691633e-02\n  2.42790106e-02 -2.94882919e-02 -3.34986032e-02  1.36103371e-02\n  2.47788867e-03 -7.65453956e-02 -7.23855976e-02 -6.48802493e-02\n -4.67204467e-02 -3.98346956e-02 -6.22799966e-02  2.14144633e-02\n  6.09602659e-03  8.24858555e-03  5.51108399e-03  6.36313824e-03\n  5.87961051e-03  4.76054708e-03  5.36249444e-03 -6.25538887e-04\n  5.77683666e-03  5.78482455e-03  3.76133303e-04  1.09571209e-02\n  8.55687376e-03  8.91081378e-02  1.38867443e-01  1.17189085e-01\n  7.48817241e-02  8.96374447e-02  9.69234364e-02  9.56841907e-02\n  7.50353323e-02  8.96054717e-02  5.46178600e-02  3.72236821e-02\n  4.10912126e-02  3.99118257e-02  4.35493463e-02  4.24890466e-02\n  4.28602741e-02  3.87376563e-02  3.71977985e-02  2.89273508e-02\n  3.40759024e-02  6.43848665e-02  6.15849911e-03  6.44208942e-04\n -3.09259997e-03  1.32164686e-02  1.72367865e-02 -9.09120115e-03\n -9.09698251e-03  1.55277923e-02  4.71421186e-03 -9.01860213e-03\n  1.66468748e-02  1.03668357e-03  1.02593413e-03 -3.57328711e-03\n -1.28142153e-02 -9.45846941e-03 -7.13603875e-03  3.24858548e-03\n  9.31980221e-03  4.03848806e-03 -5.59836033e-03].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "fea = mrmr_mid_d(X_cs12, y_cs12, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
