{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09/03/2019\n",
    "\n",
    "- Comparing the progression of different feature values over the course of the EP study for AF and non-AF patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/matthewashman/github/MasterProject2018')\n",
    "\n",
    "# Import necessary modules. Set settings. Import data.\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.robust import mad\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from FeatureExtraction.feature_tools import detect_peaks\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "import pdb\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "X = pd.read_pickle('/Users/matthewashman/github/MasterProject2018/Data/extracted_segments.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Channel', 'Coupling Interval', 'Data', 'Patient', 'S1/S2', 'Type'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Extracting Features: 100.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_list = []\n",
    "\n",
    "\n",
    "# Extract features\n",
    "for i, row in X_S2.iterrows():\n",
    "    clear_output(wait=True)\n",
    "    display('Extracting Features: ' + str(round(100*i/X_S2.index[-1],3)) + '%')\n",
    "\n",
    "    # Get typical response for this patient and channel\n",
    "    # Bad apples\n",
    "    if (((row['Type'] + row['Patient']) == 'af8') & (row['Channel'] == 'CS5-6')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[2]\n",
    "    elif (((row['Type'] + row['Patient']) == 'at1') & (row['Channel'] == 'CS1-2')):\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                           (X_S1['Patient']==row['Patient']) &\n",
    "                           (X_S1['Channel']==row['Channel'])\n",
    "                           ].sort_values(by=['Coupling Interval'], ascending=False).iloc[4]\n",
    "    else:\n",
    "        typical_response = X_S1[(X_S1['Type']==row['Type']) & \n",
    "                               (X_S1['Patient']==row['Patient']) &\n",
    "                               (X_S1['Channel']==row['Channel'])\n",
    "                               ].sort_values(by=['Coupling Interval'], ascending=False).iloc[0]\n",
    "\n",
    "    typical_feature_dict = get_good_feature_dict(typical_response['Data'])\n",
    "    feature_dict = get_good_feature_dict(row['Data'])\n",
    "\n",
    "    # Normalise by subtracting 'typical' feature values\n",
    "    for k, v in feature_dict.items():\n",
    "        feature_dict[k] = v - typical_feature_dict[k]\n",
    "\n",
    "    # Fill in the other column values\n",
    "    for col, value in row.iteritems():\n",
    "        feature_dict[col] = value\n",
    "\n",
    "    feature_list.append(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_evolution_list = []\n",
    "filled_feature_evolution_list = []\n",
    "\n",
    "patient_types = features['Type'].unique()\n",
    "cis = features['Coupling Interval'].unique()\n",
    "cis = np.sort(cis)\n",
    "feature_names = features.drop(['Type', 'Patient', 'Coupling Interval', 'Channel', 'Data', 'S1/S2'], axis=1).columns\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = features[features['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        patient_features = features[(features['Patient']==patient) & (features['Type']==patient_type)]\n",
    "        patient_cis = patient_features['Coupling Interval'].unique()\n",
    "        patient_cis = np.sort(patient_cis)\n",
    "        channels = patient_features['Channel'].unique()\n",
    "                \n",
    "        for channel in channels:\n",
    "            patient_feature_evolution_dict = {}\n",
    "            filled_patient_feature_evolution_dict = {}\n",
    "            for feature in feature_names:\n",
    "                feature_evolution = np.empty(len(cis))\n",
    "                filled_feature_evolution = np.empty(len(cis))\n",
    "                \n",
    "                filled_feature_evolution[:] = np.nan\n",
    "                feature_evolution[:] = np.nan\n",
    "                for i, ci in enumerate(cis):\n",
    "                    if ci in patient_cis:\n",
    "                        try:\n",
    "                            feature_evolution[i] = patient_features.loc[(patient_features['Coupling Interval']==ci) & (patient_features['Channel']==channel)][feature].values[0]\n",
    "                        except IndexError:\n",
    "                             continue\n",
    "\n",
    "                patient_feature_evolution_dict[feature] = feature_evolution\n",
    "                \n",
    "                # Fill in the missing values up to the last coupling interval (want to retain this information)\n",
    "                try:\n",
    "                    first_ci = np.where(~np.isnan(feature_evolution))[0][0]\n",
    "                    last_ci = np.where(~np.isnan(feature_evolution))[0][-1]\n",
    "                except IndexError:\n",
    "                    first_ci = 0\n",
    "                    last_ci = 0\n",
    "                \n",
    "                filled_feature_evolution[last_ci+1:] = 0\n",
    "                \n",
    "                for i in range(last_ci, first_ci, -1):\n",
    "                    if np.isnan(feature_evolution[i]):\n",
    "                        filled_feature_evolution[i] = feature_evolution[i+1]\n",
    "                    else:\n",
    "                        filled_feature_evolution[i] = feature_evolution[i]\n",
    "                        \n",
    "                filled_patient_feature_evolution_dict[feature] = filled_feature_evolution\n",
    "        \n",
    "            patient_feature_evolution_dict['Patient'] = patient\n",
    "            patient_feature_evolution_dict['Type'] = patient_type\n",
    "            patient_feature_evolution_dict['Channel'] = channel\n",
    "            \n",
    "            filled_patient_feature_evolution_dict['Patient'] = patient\n",
    "            filled_patient_feature_evolution_dict['Type'] = patient_type\n",
    "            filled_patient_feature_evolution_dict['Channel'] = channel\n",
    "            \n",
    "            feature_evolution_list.append(patient_feature_evolution_dict)\n",
    "            filled_feature_evolution_list.append(filled_patient_feature_evolution_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert feature_evolution_list to a DataFrame\n",
    "feature_evolution_df = pd.DataFrame(feature_evolution_list)\n",
    "filled_feature_evolution_df = pd.DataFrame(filled_feature_evolution_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Approximate Entropy: m=3 r=0.7</th>\n",
       "      <th>Channel</th>\n",
       "      <th>Conduction Delay: set_thresh=False</th>\n",
       "      <th>Index Mass Quantile: q=0.6</th>\n",
       "      <th>Label 1</th>\n",
       "      <th>Label 2</th>\n",
       "      <th>Location of Maximum Energy: M=14</th>\n",
       "      <th>Number of Peaks: set_thresh=False</th>\n",
       "      <th>Patient</th>\n",
       "      <th>Percentage Fractionation: thresh=0.01</th>\n",
       "      <th>Power Spectral Entropy</th>\n",
       "      <th>Ratio Beyond 1xSTD</th>\n",
       "      <th>Sample Entropy Around Max Energy: width=60 r=0.025</th>\n",
       "      <th>Type</th>\n",
       "      <th>Width of Maximum Energy: M=14, width_thresh=0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nan, 0.016678350605747405, 0.0049198855794055...</td>\n",
       "      <td>CS1-2</td>\n",
       "      <td>[nan, 16.0, 8.0, 4.0, 3.0, 2.0, 1.0, 0.0, 0.0,...</td>\n",
       "      <td>[nan, 0.08730158730158732, 0.03968253968253971...</td>\n",
       "      <td>[nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, 18.0, 9.0, 4.0, 3.0, 2.0, 1.0, 0.0, -1.0...</td>\n",
       "      <td>[nan, -1.0, 0.0, -1.0, 1.0, -1.0, -1.0, -2.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, 2.3999999999999995, 8.8, 1.6000000000000...</td>\n",
       "      <td>[nan, -0.12913011359661297, -0.258766185088053...</td>\n",
       "      <td>[nan, 0.031746031746031744, 0.0079365079365079...</td>\n",
       "      <td>[nan, -0.1357682250390539, -0.2027192925820090...</td>\n",
       "      <td>af</td>\n",
       "      <td>[nan, 24.0, 15.0, -8.0, -10.0, -11.0, -12.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[nan, 0.010876864735488767, 0.0133671729837686...</td>\n",
       "      <td>CS3-4</td>\n",
       "      <td>[nan, 26.0, 16.0, 6.0, 3.0, 1.0, 1.0, 0.0, -1....</td>\n",
       "      <td>[nan, 0.17460317460317462, 0.11111111111111113...</td>\n",
       "      <td>[nan, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, 19.0, 11.0, 5.0, 2.0, 0.0, 0.0, -1.0, -2...</td>\n",
       "      <td>[nan, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -...</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, 1.5999999999999996, 0.7999999999999989, ...</td>\n",
       "      <td>[nan, 0.05019840700969436, 0.2829384265266688,...</td>\n",
       "      <td>[nan, 0.015873015873015872, 0.0238095238095238...</td>\n",
       "      <td>[nan, 0.004074206569512115, 0.1295203477630996...</td>\n",
       "      <td>af</td>\n",
       "      <td>[nan, 1.0, 3.0, 2.0, -2.0, -1.0, -2.0, -1.0, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nan, 0.13403687631292605, 0.16319505003577706...</td>\n",
       "      <td>CS5-6</td>\n",
       "      <td>[nan, 31.0, 34.0, -1.0, 6.0, 1.0, -1.0, -1.0, ...</td>\n",
       "      <td>[nan, 0.35714285714285715, 0.25396825396825395...</td>\n",
       "      <td>[nan, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, 33.0, 35.0, 15.0, 3.0, 2.0, 1.0, 0.0, -1...</td>\n",
       "      <td>[nan, 5.0, 6.0, 7.0, 4.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[nan, 16.8, 18.400000000000002, 28.0, 20.00000...</td>\n",
       "      <td>[nan, -0.15624194597589458, -0.168556300993880...</td>\n",
       "      <td>[nan, 0.1349206349206349, 0.12698412698412698,...</td>\n",
       "      <td>[nan, 0.8471307620494434, 0.3528782720083229, ...</td>\n",
       "      <td>af</td>\n",
       "      <td>[nan, 38.0, 49.0, 43.0, 10.0, 7.0, 4.0, 4.0, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nan, nan, nan, -0.0011435893217871529, -0.008...</td>\n",
       "      <td>CS1-2</td>\n",
       "      <td>[nan, nan, nan, 5.0, 0.0, 0.0, -3.0, -3.0, -4....</td>\n",
       "      <td>[nan, nan, nan, 0.05555555555555558, 0.0079365...</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, nan, nan, -1.0, -7.0, 0.0, -2.0, -3.0, -...</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[nan, nan, nan, -7.2, -7.2, 0.0, 0.0, 5.599999...</td>\n",
       "      <td>[nan, nan, nan, -0.4948837666185901, -0.320082...</td>\n",
       "      <td>[nan, nan, nan, 0.047619047619047616, 0.031746...</td>\n",
       "      <td>[nan, nan, nan, 0.28728606644994353, 0.2610252...</td>\n",
       "      <td>af</td>\n",
       "      <td>[nan, nan, nan, 6.0, 4.0, 3.0, 1.0, 0.0, 3.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[nan, nan, nan, 0.020679915205361055, 0.011600...</td>\n",
       "      <td>CS3-4</td>\n",
       "      <td>[nan, nan, nan, 9.0, 3.0, 4.0, 2.0, 2.0, 0.0, ...</td>\n",
       "      <td>[nan, nan, nan, 0.047619047619047616, 0.0, 0.0...</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, nan, nan, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[nan, nan, nan, 6.0, 0.0, 2.0, 3.0, 2.0, 1.0, ...</td>\n",
       "      <td>[nan, nan, nan, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[nan, nan, nan, -1.5999999999999988, -1.599999...</td>\n",
       "      <td>[nan, nan, nan, 0.1900065619864657, 0.27280862...</td>\n",
       "      <td>[nan, nan, nan, 0.0, -0.015873015873015872, -0...</td>\n",
       "      <td>[nan, nan, nan, 0.7074216381219381, 0.13119579...</td>\n",
       "      <td>af</td>\n",
       "      <td>[nan, nan, nan, 0.0, -2.0, -1.0, 7.0, -1.0, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Approximate Entropy: m=3 r=0.7 Channel  \\\n",
       "0  [nan, 0.016678350605747405, 0.0049198855794055...   CS1-2   \n",
       "1  [nan, 0.010876864735488767, 0.0133671729837686...   CS3-4   \n",
       "2  [nan, 0.13403687631292605, 0.16319505003577706...   CS5-6   \n",
       "3  [nan, nan, nan, -0.0011435893217871529, -0.008...   CS1-2   \n",
       "4  [nan, nan, nan, 0.020679915205361055, 0.011600...   CS3-4   \n",
       "\n",
       "                  Conduction Delay: set_thresh=False  \\\n",
       "0  [nan, 16.0, 8.0, 4.0, 3.0, 2.0, 1.0, 0.0, 0.0,...   \n",
       "1  [nan, 26.0, 16.0, 6.0, 3.0, 1.0, 1.0, 0.0, -1....   \n",
       "2  [nan, 31.0, 34.0, -1.0, 6.0, 1.0, -1.0, -1.0, ...   \n",
       "3  [nan, nan, nan, 5.0, 0.0, 0.0, -3.0, -3.0, -4....   \n",
       "4  [nan, nan, nan, 9.0, 3.0, 4.0, 2.0, 2.0, 0.0, ...   \n",
       "\n",
       "                          Index Mass Quantile: q=0.6  \\\n",
       "0  [nan, 0.08730158730158732, 0.03968253968253971...   \n",
       "1  [nan, 0.17460317460317462, 0.11111111111111113...   \n",
       "2  [nan, 0.35714285714285715, 0.25396825396825395...   \n",
       "3  [nan, nan, nan, 0.05555555555555558, 0.0079365...   \n",
       "4  [nan, nan, nan, 0.047619047619047616, 0.0, 0.0...   \n",
       "\n",
       "                                             Label 1  \\\n",
       "0  [nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [nan, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [nan, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [nan, nan, nan, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                             Label 2  \\\n",
       "0  [nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [nan, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [nan, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [nan, nan, nan, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...   \n",
       "\n",
       "                    Location of Maximum Energy: M=14  \\\n",
       "0  [nan, 18.0, 9.0, 4.0, 3.0, 2.0, 1.0, 0.0, -1.0...   \n",
       "1  [nan, 19.0, 11.0, 5.0, 2.0, 0.0, 0.0, -1.0, -2...   \n",
       "2  [nan, 33.0, 35.0, 15.0, 3.0, 2.0, 1.0, 0.0, -1...   \n",
       "3  [nan, nan, nan, -1.0, -7.0, 0.0, -2.0, -3.0, -...   \n",
       "4  [nan, nan, nan, 6.0, 0.0, 2.0, 3.0, 2.0, 1.0, ...   \n",
       "\n",
       "                   Number of Peaks: set_thresh=False Patient  \\\n",
       "0  [nan, -1.0, 0.0, -1.0, 1.0, -1.0, -1.0, -2.0, ...       1   \n",
       "1  [nan, 0.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -...       1   \n",
       "2  [nan, 5.0, 6.0, 7.0, 4.0, 1.0, 1.0, 1.0, 1.0, ...       1   \n",
       "3  [nan, nan, nan, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...       2   \n",
       "4  [nan, nan, nan, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, ...       2   \n",
       "\n",
       "               Percentage Fractionation: thresh=0.01  \\\n",
       "0  [nan, 2.3999999999999995, 8.8, 1.6000000000000...   \n",
       "1  [nan, 1.5999999999999996, 0.7999999999999989, ...   \n",
       "2  [nan, 16.8, 18.400000000000002, 28.0, 20.00000...   \n",
       "3  [nan, nan, nan, -7.2, -7.2, 0.0, 0.0, 5.599999...   \n",
       "4  [nan, nan, nan, -1.5999999999999988, -1.599999...   \n",
       "\n",
       "                              Power Spectral Entropy  \\\n",
       "0  [nan, -0.12913011359661297, -0.258766185088053...   \n",
       "1  [nan, 0.05019840700969436, 0.2829384265266688,...   \n",
       "2  [nan, -0.15624194597589458, -0.168556300993880...   \n",
       "3  [nan, nan, nan, -0.4948837666185901, -0.320082...   \n",
       "4  [nan, nan, nan, 0.1900065619864657, 0.27280862...   \n",
       "\n",
       "                                  Ratio Beyond 1xSTD  \\\n",
       "0  [nan, 0.031746031746031744, 0.0079365079365079...   \n",
       "1  [nan, 0.015873015873015872, 0.0238095238095238...   \n",
       "2  [nan, 0.1349206349206349, 0.12698412698412698,...   \n",
       "3  [nan, nan, nan, 0.047619047619047616, 0.031746...   \n",
       "4  [nan, nan, nan, 0.0, -0.015873015873015872, -0...   \n",
       "\n",
       "  Sample Entropy Around Max Energy: width=60 r=0.025 Type  \\\n",
       "0  [nan, -0.1357682250390539, -0.2027192925820090...   af   \n",
       "1  [nan, 0.004074206569512115, 0.1295203477630996...   af   \n",
       "2  [nan, 0.8471307620494434, 0.3528782720083229, ...   af   \n",
       "3  [nan, nan, nan, 0.28728606644994353, 0.2610252...   af   \n",
       "4  [nan, nan, nan, 0.7074216381219381, 0.13119579...   af   \n",
       "\n",
       "     Width of Maximum Energy: M=14, width_thresh=0.2  \n",
       "0  [nan, 24.0, 15.0, -8.0, -10.0, -11.0, -12.0, -...  \n",
       "1  [nan, 1.0, 3.0, 2.0, -2.0, -1.0, -2.0, -1.0, -...  \n",
       "2  [nan, 38.0, 49.0, 43.0, 10.0, 7.0, 4.0, 4.0, 2...  \n",
       "3  [nan, nan, nan, 6.0, 4.0, 3.0, 1.0, 0.0, 3.0, ...  \n",
       "4  [nan, nan, nan, 0.0, -2.0, -1.0, 7.0, -1.0, 0....  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_feature_evolution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "# Comparing fractionation label curves between patient types\n",
    "colours = ['#e25238', '#6997e5']\n",
    "patients_of_interest = ['af', 'ep']\n",
    "labels = [1,0]\n",
    "\n",
    "features_to_remove = ['Label 1', 'Label 2', 'Conduction Delay: set_thresh=False', 'Power Spectral Entropy']\n",
    "features_of_interest = [f for f in feature_names if f not in features_to_remove]\n",
    "\n",
    "features_of_interest1 = features_of_interest[:(round(len(features_of_interest)/2))]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(features_of_interest1), ncols=3, figsize=(16, 9))\n",
    "for patient_type, colour in zip(patients_of_interest, colours):\n",
    "    patients = feature_evolution_df[feature_evolution_df['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        for i,feature in enumerate(features_of_interest1):\n",
    "            x = np.arange(230, 410, 10)\n",
    "            try:\n",
    "                cs12_feature_ev = np.squeeze(feature_evolution_df.loc[(feature_evolution_df['Type']==patient_type) & \n",
    "                                                                      (feature_evolution_df['Patient']==patient) &\n",
    "                                                                      (feature_evolution_df['Channel']=='CS1-2')\n",
    "                                                                      ][feature].values[0])\n",
    "            except IndexError:\n",
    "                cs12_feature_ev = np.empty(len(x))\n",
    "                cs12_feature_ev[:] = np.nan\n",
    "                \n",
    "            x_cs12 = x[~np.isnan(cs12_feature_ev)]\n",
    "            cs12_feature_ev = cs12_feature_ev[~np.isnan(cs12_feature_ev)]\n",
    "            \n",
    "            try:\n",
    "                cs34_feature_ev = np.squeeze(feature_evolution_df.loc[(feature_evolution_df['Type']==patient_type) & \n",
    "                                                                      (feature_evolution_df['Patient']==patient) &\n",
    "                                                                      (feature_evolution_df['Channel']=='CS3-4')\n",
    "                                                                      ][feature].values[0])\n",
    "            except IndexError:\n",
    "                cs34_feature_ev = np.empty(len(x))\n",
    "                cs34_feature_ev[:] = np.nan\n",
    "                \n",
    "            x_cs34 = x[~np.isnan(cs34_feature_ev)]\n",
    "            cs34_feature_ev = cs34_feature_ev[~np.isnan(cs34_feature_ev)]\n",
    "            \n",
    "            try:\n",
    "                cs56_feature_ev = np.squeeze(feature_evolution_df.loc[(feature_evolution_df['Type']==patient_type) & \n",
    "                                                                     (feature_evolution_df['Patient']==patient) &\n",
    "                                                                     (feature_evolution_df['Channel']=='CS5-6')\n",
    "                                                                     ][feature].values[0])\n",
    "            except IndexError:\n",
    "                cs56_feature_ev = np.empty(len(x))\n",
    "                cs56_feature_ev[:] = np.nan\n",
    "                \n",
    "            x_cs56 = x[~np.isnan(cs56_feature_ev)]\n",
    "            cs56_feature_ev = cs56_feature_ev[~np.isnan(cs56_feature_ev)]\n",
    "\n",
    "            # Plot conduction delay curves for patient\n",
    "            axes[i,0].plot(x_cs12, cs12_feature_ev, color=colour, alpha=0.7)\n",
    "            axes[i,1].plot(x_cs34, cs34_feature_ev, color=colour, alpha=0.7)\n",
    "            axes[i,2].plot(x_cs56, cs56_feature_ev, color=colour, alpha=0.7)\n",
    "\n",
    "for ax, feature in zip(axes[:,1], features_of_interest1):\n",
    "    ax.set_title(feature, fontsize=8)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlim(200,400)\n",
    "    ax.grid()\n",
    "    \n",
    "        \n",
    "plt.suptitle('Fractionation Labels for AF (red) and EP (blue).')\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.05, hspace=0.35)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Current average curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "# Comparing fractionation label curves between patient types\n",
    "colours = ['#e25238', '#6997e5']\n",
    "patients_of_interest = ['af', 'avnrt']\n",
    "labels = [1,0]\n",
    "\n",
    "features_to_remove = ['Label 2', 'Conduction Delay: set_thresh=False', 'Power Spectral Entropy']\n",
    "features_of_interest = [f for f in feature_names if f not in features_to_remove]\n",
    "\n",
    "features_of_interest1 = features_of_interest[:(round(len(features_of_interest)/2))]\n",
    "features_of_interest2 = features_of_interest[(round(len(features_of_interest)/2)):]\n",
    "features_of_interest3 = ['Location of Maximum Energy: M=14', 'Number of Peaks: set_thresh=False']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=len(features_of_interest3), ncols=3, figsize=(16, 9))\n",
    "for patient_type, colour in zip(patients_of_interest, colours):\n",
    "    patients = filled_feature_evolution_df[filled_feature_evolution_df['Type']==patient_type]['Patient'].unique()\n",
    "    for patient in patients:\n",
    "        for i,feature in enumerate(features_of_interest3):\n",
    "            x = np.arange(230, 410, 10)\n",
    "            try:\n",
    "                cs12_feature_ev = np.squeeze(filled_feature_evolution_df.loc[(filled_feature_evolution_df['Type']==patient_type) & \n",
    "                                                                            (filled_feature_evolution_df['Patient']==patient) &\n",
    "                                                                            (filled_feature_evolution_df['Channel']=='CS1-2')\n",
    "                                                                            ][feature].values[0])\n",
    "            except IndexError:\n",
    "                cs12_feature_ev = np.empty(len(x))\n",
    "                cs12_feature_ev[:] = np.nan\n",
    "                \n",
    "            x_cs12 = x[~np.isnan(cs12_feature_ev)]\n",
    "            cs12_feature_ev = cs12_feature_ev[~np.isnan(cs12_feature_ev)]\n",
    "            \n",
    "            # Store running mean of feature values\n",
    "            cs12_feature_rm = np.zeros(len(cs12_feature_ev))\n",
    "            \n",
    "            for j in range(len(cs12_feature_ev)):\n",
    "                end_idx = min(len(cs12_feature_ev), j+3)\n",
    "                cs12_feature_rm[j] = np.mean(cs12_feature_ev[j:end_idx])\n",
    "                            \n",
    "            try:\n",
    "                cs34_feature_ev = np.squeeze(filled_feature_evolution_df.loc[(filled_feature_evolution_df['Type']==patient_type) & \n",
    "                                                                            (filled_feature_evolution_df['Patient']==patient) &\n",
    "                                                                            (filled_feature_evolution_df['Channel']=='CS3-4')\n",
    "                                                                            ][feature].values[0])\n",
    "            except IndexError:\n",
    "                cs34_feature_ev = np.empty(len(x))\n",
    "                cs34_feature_ev[:] = np.nan\n",
    "                \n",
    "            x_cs34 = x[~np.isnan(cs34_feature_ev)]\n",
    "            cs34_feature_ev = cs34_feature_ev[~np.isnan(cs34_feature_ev)]\n",
    "            \n",
    "            # Store running mean of feature values\n",
    "            cs34_feature_rm = np.zeros(len(cs34_feature_ev))\n",
    "            \n",
    "            for j in range(len(cs34_feature_ev)):\n",
    "                end_idx = min(len(cs12_feature_ev), j+3)\n",
    "                cs34_feature_rm[j] = np.mean(cs34_feature_ev[j:end_idx])\n",
    "            \n",
    "            try:\n",
    "                cs56_feature_ev = np.squeeze(filled_feature_evolution_df.loc[(filled_feature_evolution_df['Type']==patient_type) & \n",
    "                                                                           (filled_feature_evolution_df['Patient']==patient) &\n",
    "                                                                           (filled_feature_evolution_df['Channel']=='CS5-6')\n",
    "                                                                           ][feature].values[0])\n",
    "            except IndexError:\n",
    "                cs56_feature_ev = np.empty(len(x))\n",
    "                cs56_feature_ev[:] = np.nan\n",
    "                \n",
    "            x_cs56 = x[~np.isnan(cs56_feature_ev)]\n",
    "            cs56_feature_ev = cs56_feature_ev[~np.isnan(cs56_feature_ev)]\n",
    "            \n",
    "            # Store running mean of feature values\n",
    "            cs56_feature_rm = np.zeros(len(cs56_feature_ev))\n",
    "            \n",
    "            for j in range(len(cs56_feature_ev)):\n",
    "                end_idx = min(len(cs12_feature_ev), j+3)\n",
    "                cs56_feature_rm[j] = np.mean(cs56_feature_ev[j:end_idx])\n",
    "\n",
    "            # Plot conduction delay curves for patient\n",
    "            axes[i,0].plot(x_cs12, cs12_feature_rm, color=colour, alpha=0.7)\n",
    "            axes[i,1].plot(x_cs34, cs34_feature_rm, color=colour, alpha=0.7)\n",
    "            axes[i,2].plot(x_cs56, cs56_feature_rm, color=colour, alpha=0.7)\n",
    "\n",
    "for ax, feature in zip(axes[:,1], features_of_interest3):\n",
    "    ax.set_title(feature, fontsize=8)\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlim(200,400)\n",
    "    ax.grid()\n",
    "    \n",
    "        \n",
    "plt.suptitle('Running Average (N=3) Feature Values for AF (red) and AVNRT (blue).')\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.05, hspace=0.35)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs34_1_peak = features[(features['Number of Peaks: set_thresh=False']==1) & (features['Channel']=='CS3-4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: MatplotlibDeprecationWarning: axes.hold is deprecated.\n",
      "    See the API Changes document (http://matplotlib.org/api/api_changes.html)\n",
      "    for more details.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:39: MatplotlibDeprecationWarning: axes.hold is deprecated.\n",
      "    See the API Changes document (http://matplotlib.org/api/api_changes.html)\n",
      "    for more details.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: MatplotlibDeprecationWarning: axes.hold is deprecated.\n",
      "    See the API Changes document (http://matplotlib.org/api/api_changes.html)\n",
      "    for more details.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-4e7847ca79f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mci\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_cis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mcs12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coupling Interval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Channel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'CS1-2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mcs12_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coupling Interval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Channel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'CS1-2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Label 1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcs12_num_peaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coupling Interval'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mci\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Channel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'CS1-2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Number of Peaks: set_thresh=False'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "patient_types = features['Type'].unique()\n",
    "\n",
    "patient_types = ['avnrt', 'ep']\n",
    "\n",
    "for patient_type in patient_types:\n",
    "    patients = features[features['Type']==patient_type]['Patient'].unique()\n",
    "    if patient_type == 'avrt':\n",
    "        patients = patients[1:]\n",
    "        \n",
    "    for patient in patients: \n",
    "        patient_features = features[(features['Type']==patient_type) & (features['Patient']==patient) & (features['S1/S2']=='S2')]\n",
    "        \n",
    "        patient_cis = patient_features['Coupling Interval'].unique()\n",
    "\n",
    "        fig, axes = plt.subplots(nrows=len(patient_cis), ncols=3, sharex=True, figsize=(16,9))\n",
    "        \n",
    "        for i,ci in enumerate(patient_cis):\n",
    "            cs12 = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS1-2'))]['Data'].values[0]\n",
    "            cs12_label = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS1-2'))]['Label 1'].values[0]\n",
    "            cs12_num_peaks = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS1-2'))]['Number of Peaks: set_thresh=False'].values[0]\n",
    "            cs34 = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS3-4'))]['Data'].values[0]\n",
    "            cs34_label = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS3-4'))]['Label 1'].values[0]\n",
    "            cs34_num_peaks = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS3-4'))]['Number of Peaks: set_thresh=False'].values[0]\n",
    "            cs56 = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS5-6'))]['Data'].values[0]\n",
    "            cs56_label = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS5-6'))]['Label 1'].values[0]\n",
    "            cs56_num_peaks = patient_features[(patient_features['Coupling Interval']==ci) & ((patient_features['Channel']=='CS5-6'))]['Number of Peaks: set_thresh=False'].values[0]\n",
    "            \n",
    "            cs12_peaks = get_peaks(cs12, 0.2)\n",
    "            cs34_peaks = get_peaks(cs34, 0.2)\n",
    "            cs56_peaks = get_peaks(cs56, 0.2)\n",
    "            \n",
    "            axes[i][0].plot(np.arange(len(cs12)), cs12)\n",
    "            axes[i][0].hold(True)\n",
    "            axes[i][0].plot(cs12_peaks[0], cs12_peaks[1], 'kx')\n",
    "            plt.text(0.8, 0.3, 'Label: ' + cs12_label, fontweight='bold', fontsize=8, transform=axes[i][0].transAxes)\n",
    "            plt.text(0.8, 0.6, 'Peaks: ' + str(cs12_num_peaks), fontweight='bold', fontsize=8, transform=axes[i][0].transAxes)\n",
    "            axes[i][1].plot(np.arange(len(cs34)), cs34)\n",
    "            axes[i][1].hold(True)\n",
    "            axes[i][1].plot(cs34_peaks[0], cs34_peaks[1], 'kx')\n",
    "            plt.text(0.8, 0.3, 'Label: ' + cs34_label, fontweight='bold', fontsize=8, transform=axes[i][1].transAxes)\n",
    "            plt.text(0.8, 0.6, 'Peaks: ' + str(cs34_num_peaks), fontweight='bold', fontsize=8, transform=axes[i][1].transAxes)\n",
    "            axes[i][2].plot(np.arange(len(cs56)), cs56)\n",
    "            axes[i][2].hold(True)\n",
    "            axes[i][2].plot(cs56_peaks[0], cs56_peaks[1], 'kx')\n",
    "            plt.text(0.8, 0.3, 'Label: ' + cs56_label, fontweight='bold', fontsize=8, transform=axes[i][2].transAxes)\n",
    "            plt.text(0.8, 0.6, 'Peaks: ' + str(cs56_num_peaks), fontweight='bold', fontsize=8, transform=axes[i][2].transAxes)\n",
    "\n",
    "            \n",
    "        \n",
    "        plt.suptitle('Convolved signal for: ' + patient_type + ' ' + patient)\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shitty conduction delay detector\n",
    "def get_delay(x, amp_thresh=None, set_thresh=False):\n",
    "    if (set_thresh==True):\n",
    "        if any(abs(x)>amp_thresh):\n",
    "            return np.argmax(abs(x)>amp_thresh)\n",
    "        else:\n",
    "            return len(x)\n",
    "    else:    \n",
    "        return np.argmax(abs(x)>(max(abs(x))/2))\n",
    "    \n",
    "def denoise(x):\n",
    "    # Obtain Daubechies N=6 wavelet coefficients\n",
    "    waveletCoefs = pywt.wavedec(x, 'db7', mode='per')\n",
    "\n",
    "    # Throw away coefficients corresponding to noise\n",
    "    sigma = mad(waveletCoefs[-1])\n",
    "    uThresh = 1*sigma*np.sqrt(2*np.log(len(x)))\n",
    "    denoised = waveletCoefs[:]\n",
    "    denoised[1:] = (pywt._thresholding.hard(i, value=uThresh) for i in denoised[1:])\n",
    "\n",
    "    # Reconstruct the original signal\n",
    "    xDenoised = pywt.waverec(denoised, 'db7', mode='per')\n",
    "\n",
    "    return xDenoised\n",
    "\n",
    "def get_peaks(x, height_thresh, scale_amp=None, set_scale=False, plot = False):\n",
    "    x = np.array(x)\n",
    "    \n",
    "    # Get height_thresh\n",
    "    if set_scale:\n",
    "        height_thresh = height_thresh*scale_amp\n",
    "    else:\n",
    "        height_thresh = height_thresh*max(abs(x))\n",
    "    \n",
    "    # Denoise x\n",
    "    xdn = denoise(x)\n",
    "\n",
    "    # Detect peaks using detect_peaks\n",
    "    pos_peak_idx = detect_peaks(xdn, mph=height_thresh, threshold = 0)\n",
    "    neg_peak_idx = detect_peaks((-xdn), mph=height_thresh, threshold = 0)\n",
    "    peak_idx = np.concatenate([pos_peak_idx, neg_peak_idx])\n",
    "    peak_idx = np.sort(peak_idx)\n",
    "    # Edge indeces aren't detected\n",
    "    peak_idx = peak_idx[(peak_idx != 0) & (peak_idx != (len(xdn)-1))]\n",
    "\n",
    "    new_peak_idx = []\n",
    "    peak_amp = []\n",
    "    if (len(peak_idx) > 0):\n",
    "        new_peak_idx.append(peak_idx[0])\n",
    "        mp_thresh = 0.2*max(abs(x))\n",
    "        for i in range(len(peak_idx)-1):\n",
    "            idx = peak_idx[i]\n",
    "            idx_next = peak_idx[i+1]\n",
    "            mid_point = int((idx_next+idx)/2)\n",
    "            if (max([abs(x[idx_next]-x[mid_point]), abs(x[idx]-x[mid_point])]) > mp_thresh):\n",
    "                new_peak_idx.append(idx_next)\n",
    "\n",
    "        peak_idx = np.array(new_peak_idx)\n",
    "        peak_amp = x[peak_idx]\n",
    "\n",
    "    if plot == True:\n",
    "        fig, [ax1] = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(8,8))\n",
    "        ax1.plot(x, 'b' , xdn, 'r--', peak_idx, peak_amp, 'kx')\n",
    "        #plt.title(fileName)\n",
    "        ax1.set_xlabel('Sample')\n",
    "        ax1.set_ylabel('Normalised amplitude')\n",
    "        ax1.legend(['Original segment', 'Denoised segment', 'Detected peaks'])\n",
    "\n",
    "        plt.draw()\n",
    "        plt.waitforbuttonpress(0) # this will wait for indefinite time\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "    return peak_idx, peak_amp\n",
    "\n",
    "def sample_entropy(U, m, r):\n",
    "\n",
    "    def _maxdist(x_i, x_j):\n",
    "        result = max([abs(ua-va) for ua, va in zip(x_i, x_j)])\n",
    "        return result\n",
    "\n",
    "    def _phi(m):\n",
    "        x = np.zeros([N,m-1])\n",
    "        for i in range(N-m+1):\n",
    "            x[i,:] = U[i:i+m-1]\n",
    "\n",
    "        C = 0\n",
    "        for i in range(len(x)):\n",
    "            for j in range(len(x)):\n",
    "                if i != j:\n",
    "                    if _maxdist(x[i,:], x[j,:]) <= r:\n",
    "                        C = C + 1\n",
    "\n",
    "        return C\n",
    "\n",
    "    U = U/max(abs(U))\n",
    "    N = len(U)\n",
    "\n",
    "    return -np.log(_phi(m+1)/_phi(m))\n",
    "\n",
    "def percentage_fractionation(x, peak_idxs, thresh=0.01, sr=1000):\n",
    "    # Get peak indexes and amplitude\n",
    "    peak_idx_diffs = np.diff(peak_idxs)\n",
    "    frac_time = 0\n",
    "    frac_time = np.sum(peak_idx_diffs[peak_idx_diffs < thresh*sr])\n",
    "    prcnt_frac = (frac_time/len(x))*100\n",
    "    return prcnt_frac\n",
    "\n",
    "def get_local_sample_entropy(x, centre_idx, width, m=2, r=0.05):\n",
    "    # Ensure width is odd\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return sample_entropy(x[:width+1], m, r)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return sample_entropy(x[len(x)-1-width:], m, r)\n",
    "    else:\n",
    "        return sample_entropy(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], m, r)\n",
    "    \n",
    "def get_location_of_max_energy(x, M=14):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    return (np.argmax(x_) + math.floor(M/2))\n",
    "        \n",
    "def get_local_peaks(x, centre_idx, width=25, height_thresh=0.1):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_peaks(x[:width+1], height_thresh)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_peaks(x[len(x)-1-width:], height_thresh)\n",
    "    else:\n",
    "        return get_peaks(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)], height_thresh)\n",
    "    \n",
    "def get_pse(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_P = (1/len(x_fft))*np.absolute(x_fft)**2\n",
    "    x_p = x_P/sum(x_P)\n",
    "    pse = np.sum([(-p*np.log2(p)) for p in x_p])\n",
    "    if pse == np.nan:\n",
    "        pdb.set_trace()\n",
    "        print('WTF')\n",
    "    return pse\n",
    "\n",
    "def get_local_pse(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_pse(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_pse(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_pse(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_spectral_centroid(x):\n",
    "    x_fft = np.fft.rfft(x)\n",
    "    x_spectrum = np.absolute(x_fft)\n",
    "    normalized_spectrum = x_spectrum/sum(x_spectrum)\n",
    "    normalized_frequencies = np.arange(0, len(x_spectrum), 1)\n",
    "    return sum(normalized_frequencies * normalized_spectrum)\n",
    "\n",
    "def get_local_spectral_centroid(x, centre_idx, width=50):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return get_spectral_centroid(x[:width+1])\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return get_spectral_centroid(x[len(x)-1-width:])\n",
    "    else:\n",
    "        return get_spectral_centroid(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)])\n",
    "    \n",
    "def get_local_energy(x, centre_idx, width=60):\n",
    "    if ((width%2) == 0):\n",
    "        width += 1\n",
    "        \n",
    "    if (centre_idx < (width-1)/2):\n",
    "        return np.sum(x[:width+1]**2)\n",
    "    elif (centre_idx > (len(x)-1-(width-1)/2)):\n",
    "        return np.sum(x[len(x)-1-width:]**2)\n",
    "    else:\n",
    "        return np.sum(x[int(centre_idx-(width-1)/2):int(centre_idx+(width+1)/2)]**2)\n",
    "    \n",
    "def get_width_max_energy(x, M=14, width_thresh=0.2):\n",
    "    v = np.ones(M)\n",
    "    x_ = np.convolve(abs(x), v)\n",
    "    if any(x_[np.argmax(x_):] < width_thresh*np.max(x_)):\n",
    "        end_idx = np.argmax(x_) + np.argmax(x_[np.argmax(x_):] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        end_idx = len(x_)-1\n",
    "    if any(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_)):  \n",
    "        start_idx = np.argmax(x_) - np.argmax(x_[np.argmax(x_)::-1] < width_thresh*np.max(x_))\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    return (end_idx - start_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 300\n"
     ]
    }
   ],
   "source": [
    "def get_good_feature_dict(x, col_prefix=''):\n",
    "    feature_dict = {}\n",
    "    height_thresh=0.2\n",
    "    \n",
    "#     feature_dict[col_prefix + 'Maximum Absolute Value'] = max(abs(x))\n",
    "    \n",
    "    # Hand engineered features\n",
    "    x = x/max(abs(x))\n",
    "    feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation: thresh=0.01'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    \n",
    "    # Denoise x for remaining features\n",
    "    x = denoise(x)\n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy: M=14'] = max_energy_idx\n",
    "    feature_dict[col_prefix + 'Sample Entropy Around Max Energy: width=60 r=0.025'] = get_local_sample_entropy(x, max_energy_idx, 60, m=2, r=0.025)\n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy: M=14, width_thresh=0.2'] = get_width_max_energy(x, M=14, width_thresh=0.2)\n",
    "    \n",
    "    # Temporal features\n",
    "    feature_dict[col_prefix + 'Approximate Entropy: m=3 r=0.7'] = feature_calculators.approximate_entropy(x, 3, 0.7)\n",
    "    imq = feature_calculators.index_mass_quantile(x, [{'q': 0.6}])\n",
    "    feature_dict[col_prefix + 'Index Mass Quantile: q=0.6'] = imq[0][1]\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 1xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 1)\n",
    "    \n",
    "    # Spectral features\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy'] = get_pse(x)\n",
    "    \n",
    "    return feature_dict\n",
    "    \n",
    "\n",
    "def get_hand_engineered_feature_dict(x, thresh_cd=None, set_thresh_cd=False, thresh_peaks=None, set_thresh_peaks=False, show_peaks=False, col_prefix = ''):\n",
    "    feature_dict = {}\n",
    "    sf = max(abs(x))\n",
    "    x = x/max(abs(x))\n",
    "\n",
    "    # Hand engineered features\n",
    "    if set_thresh_cd:\n",
    "        thresh_cd = thresh_cd/sf\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=True'] = get_delay(x, thresh_cd, set_thresh_cd)\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "    else:\n",
    "        feature_dict[col_prefix + 'Conduction Delay: set_thresh=False'] = get_delay(x)\n",
    "    \n",
    "    height_thresh=0.1\n",
    "    if set_thresh_peaks:\n",
    "        thresh_peaks = thresh_peaks/sf\n",
    "        peaks = get_peaks(x, height_thresh, thresh_peaks, set_thresh_peaks, plot=False)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=True'] = len(peaks[0])\n",
    "        peaks = get_peaks(x, height_thresh)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    else:\n",
    "        peaks = get_peaks(x, height_thresh)\n",
    "        feature_dict[col_prefix + 'Number of Peaks: set_thresh=False'] = len(peaks[0])\n",
    "    \n",
    "    peaks = get_peaks(x, height_thresh)\n",
    "    feature_dict[col_prefix + 'Percentage Fractionation: thresh=0.01'] = percentage_fractionation(x, peaks[0], thresh=0.01)\n",
    "    \n",
    "    # Denoise x for remaining features\n",
    "    x = denoise(x)\n",
    "    \n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Location of Maximum Energy: M=14'] = max_energy_idx\n",
    "    feature_dict[col_prefix + 'Sample Entropy Around Max Energy: width=60 r=0.025'] = get_local_sample_entropy(x, max_energy_idx, 60, m=2, r=0.025)\n",
    "    feature_dict[col_prefix + 'Energy Around Max Energy'] = get_local_energy(x, max_energy_idx, 60)\n",
    "    min_idx = np.argmin(x)\n",
    "    max_idx = np.argmax(x)\n",
    "    feature_dict[col_prefix + 'Peaks Between Min and Max'] = len([i for i in peaks[0] if ((i > min_idx) & (i < max_idx))])\n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy: M=14, width_thresh=0.4'] = get_width_max_energy(x, M=14, width_thresh=0.4)\n",
    "    feature_dict[col_prefix + 'Width of Maximum Energy: M=14, width_thresh=0.2'] = get_width_max_energy(x, M=14, width_thresh=0.2)\n",
    "\n",
    "    return feature_dict\n",
    "\n",
    "def get_spectral_feature_dict(x, col_prefix = ''):\n",
    "    feature_dict = {}\n",
    "    # Denoise and normalise x for remaining features\n",
    "    x = denoise(x)\n",
    "    x = x/max(abs(x))\n",
    "    \n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy'] = get_pse(x)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid'] = get_spectral_centroid(x)\n",
    "    max_energy_idx = get_location_of_max_energy(x)\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy Around Maximum Energy: width=30'] = get_local_pse(x, max_energy_idx, width=30)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid Around Maximum Energy: width=30'] = get_local_spectral_centroid(x, max_energy_idx, width=30)\n",
    "    feature_dict[col_prefix + 'Power Spectral Entropy Around Maximum Energy: width=60'] = get_local_pse(x, max_energy_idx, width=60)\n",
    "    feature_dict[col_prefix + 'Spectral Centroid Around Maximum Energy: width=60'] = get_local_spectral_centroid(x, max_energy_idx, width=60)\n",
    "    \n",
    "    return feature_dict\n",
    "    \n",
    "def get_temporal_feature_dict(x, col_prefix = ''):\n",
    "\n",
    "    feature_dict = {}\n",
    "    feature_dict[col_prefix + 'Maximum Absolute Value'] = np.max(abs(x))\n",
    "    \n",
    "    # Denoise and normalise x for remaining features\n",
    "    x = denoise(x)\n",
    "    x = x/max(abs(x))\n",
    "\n",
    "\n",
    "    erbc = feature_calculators.energy_ratio_by_chunks(x, [{'num_segments':10, 'segment_focus':3}, {'num_segments':10, 'segment_focus':2}])\n",
    "    feature_dict[col_prefix + 'Energy Ratio by Chunks: num_segments=10 segment_focus=2'] = erbc[1][1]\n",
    "    feature_dict[col_prefix + 'Energy Ratio by Chunks: num_segments=10 segment_focus=3'] = erbc[0][1]\n",
    "    feature_dict[col_prefix + 'Approximate Entropy: m=3 r=0.7'] = feature_calculators.approximate_entropy(x, 3, 0.7)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 5xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 5)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 4xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 4)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 3xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 3)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 2xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 2)\n",
    "    feature_dict[col_prefix + 'Ratio Beyond 1xSTD'] = feature_calculators.ratio_beyond_r_sigma(x, 1)\n",
    "    # A fraction q of the mass lies to the left of i. (Alternative to conduction delay?)\n",
    "    imq = feature_calculators.index_mass_quantile(x, [{'q': 0.6}, {'q': 0.4}])\n",
    "    feature_dict[col_prefix + 'Index Mass Quantile: q=0.6'] = imq[0][1]\n",
    "    feature_dict[col_prefix + 'Index Mass Quantile: q=0.4'] = imq[1][1]\n",
    "    \n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
